


import numpy as np
import pandas as pd


import matplotlib.pyplot as plt
import seaborn as sns 

%matplotlib inline





data = pd.read_csv('HR-Employee-Attrition.csv')

display( data.head().style.background_gradient(cmap='BuPu') )








### TO BE COMPLETED ###
print(len(data))








### TO BE COMPLETED ###
print('Number of duplicated lines:', data.duplicated().sum())
print('')

df = pd.DataFrame({
    'Unique':data.nunique(),
    'Null':data.isna().sum(),
    'NullPercent':data.isna().sum() / len(data),
    'Type':data.dtypes.values
})
display(df)


# %load solutions/data_quality.py
print('Number of duplicated lines:', data.duplicated().sum())
print('')

df = pd.DataFrame({
    'Unique':data.nunique(),
    'Null':data.isna().sum(),
    'NullPercent':data.isna().sum() / len(data),
    'Type':data.dtypes.values
})
display(df)








### TO BE COMPLETED ###
data = data.drop(['EmployeeCount', 'Over18', 'StandardHours', 'EmployeeNumber'], axis=1) #axis=1 pour supprimer des colonnes (0 pour des lignes)
display( data.head().style.background_gradient(cmap='BuPu') )


# %load solutions/data_drop.py





num = data.select_dtypes(exclude='O')
display(num.head())


cat = data.select_dtypes(include='O')
display(cat.head())





### TO BE COMPLETED ###
print('Quantitative data:', round(100*num.shape[1]/data.shape[1],2), '%')
print('Qualitative data:', round(100*cat.shape[1]/data.shape[1],2), '%')



# %load solutions/data_proportion.py






### TO BE COMPLETED ###
display( data.describe().T.style.background_gradient(cmap='BuPu') ) #T pour la trasnpos√©e



# %load solutions/stat_summary.py
print( data.describe().T )
display( data.describe().T.style.background_gradient(cmap='BuPu') )








### TO BE COMPLETED ###
plt.figure(figsize=(18,9))

# correlation between columns
sns.heatmap(data.corr(numeric_only=True), annot=True, fmt='.1f')
plt.xticks(rotation=40)

plt.show()

# --- #

# strong correlation between columns
cols = ['Education','Age','MonthlyIncome','JobLevel','NumCompaniesWorked','TotalWorkingYears','YearsAtCompany',
       'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']
sns.heatmap(data[cols].corr(), annot=True, fmt='.1f')
plt.xticks(rotation=40)
plt.show()



# %load solutions/data_correlation.py





### TO BE COMPLETED ###
cols = ['TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'Attrition']

sns.pairplot(data[cols], hue = 'Attrition', palette={'Yes': 'mediumvioletred', 'No': 'cornflowerblue'})
plt.show()

[...]


# %load solutions/data_pairplot.py
cols = ['TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'Attrition']

sns.pairplot(data[cols], hue = 'Attrition', palette={'Yes': 'mediumvioletred', 'No': 'cornflowerblue'})
plt.show()





### TO BE COMPLETED ###

[...]


# %load solutions/history.py
cols = ['YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion']

fig,axes = plt.subplots(nrows=3, ncols=1, figsize=(10,10))

for i,c in enumerate(cols):
    sns.pointplot(x=data[c], y=data['TotalWorkingYears'], ax=axes[i], hue=data['Attrition'], palette={'Yes':'mediumvioletred', 'No':'cornflowerblue'})
    axes[i].set_xlabel(c)
    axes[i].set_ylabel('TotalWorkingYears')

plt.tight_layout()
plt.show()














### TO BE COMPLETED ###

[...]


# %load solutions/overtime.py
plt.figure(figsize=(10,8))

# --- #

plt.subplot(2,2,1)
sns.histplot(data, x="MaritalStatus", hue="OverTime", palette="rocket")
plt.title('Overtime by Marital Status')

# --- #

plt.subplot(2,2,2)
sns.histplot(data, x="Department", hue="OverTime", palette="rocket")
# plt.xticks(rotation=35)
plt.title('Overtime by Department')

# --- #

plt.subplot(2,2,3)
sns.histplot(data, x="Gender", hue="OverTime", palette="rocket")
plt.title('Overtime by Gender')

# --- #

plt.subplot(2,2,4)
sns.histplot(data, x='Age', hue='OverTime', palette="rocket", kde=True)
plt.title('Distribution of Age by OverTime')

plt.tight_layout()
plt.show()











### TO BE COMPLETED ###

[...]


# %load solutions/attrition.py
plt.figure(figsize=(10,8))

# --- #

plt.subplot(2,2,1)
sns.histplot(data, x="MaritalStatus", hue="Attrition", palette={'Yes':'mediumvioletred', 'No':'cornflowerblue'})
plt.title('Attrition by Marital Status')

# --- #

plt.subplot(2,2,2)
sns.histplot(data, x="Department", hue="Attrition", palette={'Yes':'mediumvioletred', 'No':'cornflowerblue'})
# plt.xticks(rotation=35)
plt.title('Attrition by Department')

# --- #

plt.subplot(2,2,3)
sns.histplot(data, x="Gender", hue="Attrition", palette={'Yes':'mediumvioletred', 'No':'cornflowerblue'})
plt.title('Attrition by Gender')

# --- #

plt.subplot(2,2,4)
sns.histplot(data, x='Age', hue='Attrition', palette={'Yes':'mediumvioletred', 'No':'cornflowerblue'}, kde=True)
plt.title('Distribution of Age by Attrition')

plt.tight_layout()
plt.show()











data.loc[data['Attrition']=='No','Attrition'] = 0
data.loc[data['Attrition']=='Yes','Attrition'] = 1

data['Attrition'] = data['Attrition'].astype('int')





BT = data['BusinessTravel'].unique()

for travel in BT:
    data['Business_'+travel] = 0
    data.loc[data['BusinessTravel']==travel,'Business_'+travel] = 1
    data['Business_'+travel] = data['Business_'+travel].astype('int')

data = data.drop('BusinessTravel',axis=1)
# data.head()





DPT = data['Department'].unique()
DPT_names = ['Sales', 'R & D', 'Dpt HR']

for i, dpt in enumerate(DPT):
    data[DPT_names[i]] = 0
    data.loc[data['Department']==dpt, DPT_names[i]] = 1
    data[DPT_names[i]] = data[DPT_names[i]].astype('int')

data = data.drop('Department',axis=1)
# data.head()





EDUC = data['EducationField'].unique()
EDUC_names = ['Life Sciences', 'Other', 'Medical', 'Marketing', 'Technical Degree', 'Educ HR']

for i, educ in enumerate(EDUC):
    data[EDUC_names[i]] = 0
    data.loc[data['EducationField']==educ, EDUC_names[i]] = 1
    data[EDUC_names[i]] = data[EDUC_names[i]].astype('int')

data = data.drop('EducationField',axis=1)
# data.head()





data.loc[data['Gender']=='Male','Gender'] = 1
data.loc[data['Gender']=='Female','Gender'] = 0

data['Gender'] = data['Gender'].astype('int')





JOB = data['JobRole'].unique()
JOB_names = JOB
JOB_names[-1] = 'Job HR'

for i, job in enumerate(JOB):
    data[JOB_names[i]] = 0
    data.loc[data['JobRole']==job, JOB_names[i]] = 1
    data[JOB_names[i]] = data[JOB_names[i]].astype('int')

data = data.drop('JobRole',axis=1)
# data.head()





STATUS = data['MaritalStatus'].unique()
STATUS_names = STATUS

for i, statues in enumerate(STATUS):
    data[STATUS_names[i]] = 0
    data.loc[data['MaritalStatus']==statues, STATUS_names[i]] = 1
    data[STATUS_names[i]] = data[STATUS_names[i]].astype('int')

data = data.drop('MaritalStatus',axis=1)
# data.head()





data.loc[data['OverTime']=='No','OverTime'] = 0
data.loc[data['OverTime']=='Yes','OverTime'] = 1

data['OverTime'] = data['OverTime'].astype('int')





data.dtypes





from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

from sklearn.linear_model import LogisticRegression





### TO BE COMPLETED ###

[...]

train_x, test_x, train_y, test_y = ...


# %load solutions/train_test_split.py
X = data.drop(['Attrition'],axis=1)
Y = data['Attrition']

train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.3, random_state=20)





### TO BE COMPLETED ###

clf = LogisticRegression(solver='newton-cholesky')
clf.fit(...)

[...]

accuracy = ...

print( classification_report( ... ) )


# %load solutions/logistic_regression.py
clf = LogisticRegression(solver='newton-cholesky')
clf.fit(train_x, train_y)

# --- #

pred_y = clf.predict(test_x)

accuracy = accuracy_score(test_y, pred_y, normalize=True, sample_weight=None)
print('Accuray:',round(100*accuracy,2), '%')
print(' ')

# --- #

print(classification_report(test_y, pred_y))








from sklearn.discriminant_analysis import LinearDiscriminantAnalysis





### TO BE COMPLETED ###

[...]


%load solutions/linear_discriminant_analysis.py








from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis





### TO BE COMPLETED ###

[...]


# %load solutions/quadratic_discriminant_analysis.py















